{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q 1\n",
        "    Implement 3 different CNN architectures with a comparison table for the MNSIT\n",
        "    dataset using the Tensorflow library.\n",
        "    Note -\n",
        "    1. The model parameters for each architecture should not be more than 8000\n",
        "    parameters\n",
        "    2. Code comments should be given for proper code understanding.\n",
        "    3. The minimum accuracy for each accuracy should be at least 96%\n"
      ],
      "metadata": {
        "id": "aaht9Dg-DevE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the first CNN architecture\n",
        "model1 = tf.keras.Sequential([\n",
        "    layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
        "    layers.Conv2D(16, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the first model\n",
        "model1.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Define the second CNN architecture\n",
        "model2 = tf.keras.Sequential([\n",
        "    layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the second model\n",
        "model2.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Define the third CNN architecture\n",
        "model3 = tf.keras.Sequential([\n",
        "    layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
        "    layers.Conv2D(8, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the third model\n",
        "model3.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRICNeTkDk6e",
        "outputId": "c0fe1f62-b5b7-4199-b4b4-3e20aceb4dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 30s 63ms/step - loss: 0.2238 - accuracy: 0.9355 - val_loss: 0.0830 - val_accuracy: 0.9759\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.0712 - accuracy: 0.9794 - val_loss: 0.0577 - val_accuracy: 0.9815\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.0465 - accuracy: 0.9863 - val_loss: 0.0479 - val_accuracy: 0.9843\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 28s 61ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.0419 - val_accuracy: 0.9850\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0391 - val_accuracy: 0.9872\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.0388 - val_accuracy: 0.9869\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0519 - val_accuracy: 0.9838\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0382 - val_accuracy: 0.9883\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0446 - val_accuracy: 0.9867\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0480 - val_accuracy: 0.9859\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 57s 119ms/step - loss: 0.2065 - accuracy: 0.9394 - val_loss: 0.0668 - val_accuracy: 0.9775\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 60s 127ms/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.0440 - val_accuracy: 0.9851\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 57s 122ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0338 - val_accuracy: 0.9887\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 56s 120ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.0306 - val_accuracy: 0.9897\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 55s 116ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0320 - val_accuracy: 0.9894\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 54s 116ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0279 - val_accuracy: 0.9916\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 54s 115ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.0277 - val_accuracy: 0.9921\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 54s 116ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 54s 116ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0342 - val_accuracy: 0.9896\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 57s 122ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0331 - val_accuracy: 0.9899\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.2813 - accuracy: 0.9192 - val_loss: 0.1294 - val_accuracy: 0.9632\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0983 - accuracy: 0.9706 - val_loss: 0.0717 - val_accuracy: 0.9779\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 17s 35ms/step - loss: 0.0658 - accuracy: 0.9807 - val_loss: 0.0618 - val_accuracy: 0.9806\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.0560 - val_accuracy: 0.9817\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0502 - val_accuracy: 0.9826\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.0498 - val_accuracy: 0.9837\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0562 - val_accuracy: 0.9811\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0487 - val_accuracy: 0.9839\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.0470 - val_accuracy: 0.9846\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0466 - val_accuracy: 0.9850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2eb0aee230>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2 \n",
        "    Implement 5 different CNN architectures with a comparison table for CIFAR 10\n",
        "    dataset using the PyTorch library\n",
        "    Note -\n",
        "    1. The model parameters for each architecture should not be more than 10000\n",
        "    parameters\n",
        "    2 Code comments should be given for proper code understanding"
      ],
      "metadata": {
        "id": "8_9A9ug_FRjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set device configuration (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the transformations for the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the first CNN architecture\n",
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(16 * 16 * 16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model1 = Net1().to(device)\n",
        "\n",
        "# Define the second CNN architecture\n",
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(32 * 16 * 16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model2 = Net2().to(device)\n",
        "\n",
        "# Define the third CNN architecture\n",
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(64 * 16 * 16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "       \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4OodF7WFP_V",
        "outputId": "cca4c94e-c1f1-4948-f543-27a210fc99a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15669458.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q 3\n",
        "    Train a Pure CNN with less than 10000 trainable parameters using the MNIST\n",
        "    Dataset having minimum validation accuracy of 99.40%\n",
        "    Note -\n",
        "    1. Code comments should be given for proper code understanding.\n",
        "    2. Implement in both PyTorch and Tensorflow respectively"
      ],
      "metadata": {
        "id": "Jx2yWQv9FmM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set device configuration (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the transformations for the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the Pure CNN model\n",
        "class PureCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PureCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1)\n",
        "        self.fc = nn.Linear(32 * 5 * 5, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the Pure CNN model\n",
        "model = PureCNN().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        train_correct += torch.sum(predicted == labels.data)\n",
        "\n",
        "    train_loss = train_loss / len(train_dataset)\n",
        "    train_accuracy = train_correct.double() / len(train_dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    valid_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            valid_loss += loss.item() * inputs.size(0)\n",
        "            valid_correct += torch.sum(predicted == labels.data)\n",
        "\n",
        "    valid_loss = valid_loss / len(test_dataset)\n",
        "    valid_accuracy = valid_correct.double() / len(test_dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - \"\n",
        "          f\"Valid Loss: {valid_loss:.4f} - Valid Accuracy: {valid_accuracy:.4f}\")\n",
        "\n",
        "    # Check for early stopping if the validation accuracy exceeds the threshold\n",
        "    if valid_accuracy >= 0.994:\n",
        "        print(\"Validation accuracy reached the threshold. Training stopped.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0BbmvzgDrIe",
        "outputId": "3470fd1c-ed98-4a47-b8dd-7d8a490887e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 43504846.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 81793176.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10864664.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7891685.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1/10 - Train Loss: 0.2146 - Train Accuracy: 0.9383 - Valid Loss: 0.0697 - Valid Accuracy: 0.9794\n",
            "Epoch 2/10 - Train Loss: 0.0662 - Train Accuracy: 0.9794 - Valid Loss: 0.0493 - Valid Accuracy: 0.9834\n",
            "Epoch 3/10 - Train Loss: 0.0485 - Train Accuracy: 0.9851 - Valid Loss: 0.0380 - Valid Accuracy: 0.9873\n",
            "Epoch 4/10 - Train Loss: 0.0399 - Train Accuracy: 0.9878 - Valid Loss: 0.0402 - Valid Accuracy: 0.9872\n",
            "Epoch 5/10 - Train Loss: 0.0336 - Train Accuracy: 0.9898 - Valid Loss: 0.0347 - Valid Accuracy: 0.9881\n",
            "Epoch 6/10 - Train Loss: 0.0285 - Train Accuracy: 0.9912 - Valid Loss: 0.0362 - Valid Accuracy: 0.9881\n",
            "Epoch 7/10 - Train Loss: 0.0246 - Train Accuracy: 0.9921 - Valid Loss: 0.0294 - Valid Accuracy: 0.9912\n",
            "Epoch 8/10 - Train Loss: 0.0211 - Train Accuracy: 0.9936 - Valid Loss: 0.0330 - Valid Accuracy: 0.9900\n",
            "Epoch 9/10 - Train Loss: 0.0189 - Train Accuracy: 0.9940 - Valid Loss: 0.0374 - Valid Accuracy: 0.9877\n",
            "Epoch 10/10 - Train Loss: 0.0167 - Train Accuracy: 0.9945 - Valid Loss: 0.0321 - Valid Accuracy: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape the input data to match the expected shape of the CNN model\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Create the Pure CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "_, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1qjdOtZHRN1",
        "outputId": "1ec93537-f57c-445d-db19-e98e9abf1187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 32s 33ms/step - loss: 0.2472 - accuracy: 0.9293 - val_loss: 0.0755 - val_accuracy: 0.9758\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0799 - accuracy: 0.9758 - val_loss: 0.0670 - val_accuracy: 0.9796\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 31s 33ms/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 0.0468 - val_accuracy: 0.9847\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.0432 - val_accuracy: 0.9866\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 32s 35ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0372 - val_accuracy: 0.9869\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0392 - accuracy: 0.9883 - val_loss: 0.0371 - val_accuracy: 0.9878\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 31s 33ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0447 - val_accuracy: 0.9855\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 31s 33ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 0.0371 - val_accuracy: 0.9878\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0359 - val_accuracy: 0.9879\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0361 - val_accuracy: 0.9889\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0361 - accuracy: 0.9889\n",
            "Test Accuracy: 0.9889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4 -\n",
        "    Design an end-to-end solution with diagrams for object detection use cases leveraging AWS cloud services and open-source tech\n",
        "    Note -\n",
        "    1. You need to use both AWS cloud services and open-source tech to design the entire solution\n",
        "    2. The pipeline should consist of a data pipeline, ml pipeline, deployment pipeline, and inference pipeline.\n",
        "    3. In the data pipeline, you would be designing how to get the data from external or existing sources and tech used for the same\n",
        "    4. In the ml pipeline, you would be designing how to train the model, and what all algorithms, techniques, etc. would you be using. Again, tech used for the same 5.\n",
        "    Since this is a deep learning project, the use of GPUs, and how effectively are you using them to optimize for cost and training time should also be taken into consideration.\n",
        "    6. In the deployment pipeline, you would be designing how effectively and efficiently you are deploying the model in the cloud,\n",
        "    7. In the inference pipeline, consider the cost of inference and its optimization\n",
        "    related to computing resources and handling external traffic\n",
        "    8. You can use any tool to design the architecture\n",
        "    9. Do mention the pros and cons of your architecture and how much further it can be optimized and its tradeoffs.\n",
        "    10. Do include a retraining approach as well.\n",
        "    11. Try to include managed AWS resources for deep learning like AWS Textract, AWS Sagemaker, etc., and not just general-purpose compute resources like S3, EC2, etc. Try to mix the best of both services\n",
        "# Question 5 -\n",
        "    In Question 4, you have designed the architecture for an object detection use case leveraging AWS Cloud, similarly, here you will be designing for Document Classification use case leveraging Azure Cloud services.\n",
        "    Note -\n",
        "    1. Most of the points are the same as in Question 4, just cloud services will change"
      ],
      "metadata": {
        "id": "TbIMFqlFOHfI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3t80GRxCZPKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}